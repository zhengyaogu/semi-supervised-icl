{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhengyaogu/miniconda3/envs/in-context-ssl/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from in_context_ssl.reasoning.template import *\n",
    "import os\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import json\n",
    "from in_context_ssl.reasoning.utils import *\n",
    "from in_context_ssl.reasoning.dataset import *\n",
    "import re\n",
    "import pandas as pd\n",
    "from in_context_ssl.grading.grader import grade_answer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_doc(doc: dict):\n",
    "    out_doc = {\n",
    "        \"question\": doc[\"turns\"][0],\n",
    "        \"answer\": doc[\"ground_truth\"],\n",
    "        \"group\": doc[\"task\"]\n",
    "    }\n",
    "    return out_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data():\n",
    "    ds = load_dataset(\"livebench/math\")[\"test\"]\n",
    "\n",
    "    train_datasets = []\n",
    "    test_datasets = []\n",
    "\n",
    "    subtasks = [\"math_comp\", \"AMPS_Hard\", \"olympiad\"]\n",
    "    remove_columns = [k for k in ds.features.keys() if k not in [\"turns\", \"ground_truth\"]]\n",
    "    for subtask in subtasks:\n",
    "        print(len(ds))\n",
    "        ds_curr = ds.filter(lambda x: x[\"task\"] == subtask)\n",
    "        cutoff = int(len(ds_curr) * 0.75)\n",
    "        print(cutoff)\n",
    "        ds_curr = ds_curr.shuffle()\n",
    "        ds_train = ds_curr.select(range(cutoff)).map(process_doc, remove_columns=remove_columns)\n",
    "        ds_test = ds_curr.select(range(cutoff, len(ds_curr))).map(process_doc, remove_columns=remove_columns)\n",
    "        train_datasets.append(ds_train)\n",
    "        test_datasets.append(ds_test)\n",
    "\n",
    "    ds_train = datasets.concatenate_datasets(train_datasets)\n",
    "    ds_test = datasets.concatenate_datasets(test_datasets)\n",
    "\n",
    "    ds_train.save_to_disk(\"in_context_ssl/reasoning/data/livebench_math_train.hf\")\n",
    "    ds_test.save_to_disk(\"in_context_ssl/reasoning/data/livebench_math_test.hf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 93/93 [00:35<00:00,  2.64 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 93/93 [00:00<00:00, 19148.31 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def add_embedding(doc: dict):\n",
    "    out_doc = {\n",
    "        \"embedding\": client.embeddings.create(\n",
    "            input = [doc[\"question\"]], model=\"text-embedding-3-large\"\n",
    "        ).data[0].embedding\n",
    "    }\n",
    "    return out_doc\n",
    "ds = load_from_disk(\"in_context_ssl/reasoning/data/livebench_math_test.hf\")\n",
    "ds = ds.map(add_embedding)\n",
    "ds.save_to_disk(\"in_context_ssl/reasoning/data/livebench_math_test_new.hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add API key\n",
    "api_key = \"\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Positive real numbers $x$ and $y$ satisfy $y^3 = x^2$ and $(y-x)^2 = 4y^2$. What is $x+y$? $\\textbf{(A)}\\ 42 \\qquad \\textbf{(B)}\\ 12 \\qquad \\textbf{(C)}\\ 36 \\qquad \\textbf{(D)}\\ 24 \\qquad \\textbf{(E)}\\ 18$ If you cannot determine the correct multiple-choice answer, take your best guess. Once you have your answer, please duplicate that letter five times in a single string. For example, if the answer is F, then write FFFFF.\n",
      "Answer: C\n",
      "\n",
      "___\n",
      "Question: Compute the geometric mean of ${1, 9}$. Please give an exact answer, and put your final answer in latex in a $\\boxed{}$ (for example, $\\boxed{5 \\sqrt[6]{-3} \\sqrt[3]{7} 5^{2/5}}$).\n",
      "Answer: 3\n",
      "\n",
      "___\n",
      "Question: Factor the following quadratic: $-5 x^2-100 x$. Please put your final answer in a $\\\\boxed{}$.\n",
      "Answer: -5x(x + 20)\n",
      "\n",
      "___\n",
      "Question: Positive real numbers $x$ and $y$ satisfy $y^3 = x^2$ and $(y-x)^2 = 4y^2$. What is $x+y$? $\\textbf{(A)}\\ 42 \\qquad \\textbf{(B)}\\ 12 \\qquad \\textbf{(C)}\\ 36 \\qquad \\textbf{(D)}\\ 24 \\qquad \\textbf{(E)}\\ 18$ If you cannot determine the correct multiple-choice answer, take your best guess. Once you have your answer, please duplicate that letter five times in a single string. For example, if the answer is F, then write FFFFF.\n",
      "Rationale: To solve for \\( x+y \\) given the equations \\( y^3 = x^2 \\) and \\( (y-x)^2 = 4y^2 \\), we can follow these steps:\n",
      "\n",
      "1. **Start with the equations**:\n",
      "   - We have \\( y^3 = x^2 \\).\n",
      "   - We also have \\( (y - x)^2 = 4y^2 \\). \n",
      "\n",
      "2. **Rearrange the second equation**:\n",
      "   - Taking the square root, we can express it as \\( y - x = 2y \\) or \\( y - x = -2y \\). \n",
      "   - From \\( y - x = 2y \\), we get \\( -x = y \\) which leads to \\( x = -y \\) (not valid since both \\( x \\) and \\( y \\) are positive).\n",
      "   - From \\( y - x = -2y \\), we rewrite it as \\( y + 2y = x \\) or \\( x = 3y \\).\n",
      "\n",
      "3. **Substitute \\( x = 3y \\) in the first equation**:\n",
      "   - From \\( y^3 = x^2 \\), substituting \\( x \\):\n",
      "   \\[\n",
      "   y^3 = (3y)^2 = 9y^2.\n",
      "   \\]\n",
      "   - Rearranging gives:\n",
      "   \\[\n",
      "   y^3 - 9y^2 = 0.\n",
      "   \\]\n",
      "\n",
      "4. **Factor out \\( y^2 \\)**:\n",
      "   \\[\n",
      "   y^2(y - 9) = 0.\n",
      "   \\]\n",
      "   - Since \\( y \\) is positive, we have \\( y - 9 = 0 \\), thus \\( y = 9 \\).\n",
      "\n",
      "5. **Find \\( x \\)**:\n",
      "   - Substitute \\( y = 9 \\) back into \\( x = 3y \\):\n",
      "   \\[\n",
      "   x = 3 \\times 9 = 27.\n",
      "   \\]\n",
      "\n",
      "6. **Calculate \\( x + y \\)**:\n",
      "   \\[\n",
      "   x + y = 27 + 9 = 36.\n",
      "   \\]\n",
      "\n",
      "Thus, the answer is \\( 36 \\).\n",
      "\n",
      "The multiple-choice answer is \\( \\textbf{(C)}\\ 36 \\).\n",
      "\n",
      "The final answer is:\n",
      "CCCCCOOO\n",
      "\n",
      "**Confidence**: 1.0\n",
      "Answer: C\n",
      "\n",
      "___\n",
      "Question: Compute the geometric mean of ${1, 9}$. Please give an exact answer, and put your final answer in latex in a $\\boxed{}$ (for example, $\\boxed{5 \\sqrt[6]{-3} \\sqrt[3]{7} 5^{2/5}}$).\n",
      "Rationale: To find the geometric mean of the numbers \\(1\\) and \\(9\\), we use the formula for the geometric mean of two numbers \\(a\\) and \\(b\\):\n",
      "\n",
      "\\[\n",
      "\\text{Geometric Mean} = \\sqrt{a \\cdot b}\n",
      "\\]\n",
      "\n",
      "In this case, \\(a = 1\\) and \\(b = 9\\). Let's compute it step by step:\n",
      "\n",
      "1. Calculate the product of \\(a\\) and \\(b\\):\n",
      "   \\[\n",
      "   1 \\cdot 9 = 9\n",
      "   \\]\n",
      "\n",
      "2. Take the square root of the product:\n",
      "   \\[\n",
      "   \\sqrt{9} = 3\n",
      "   \\]\n",
      "\n",
      "Thus, the geometric mean of the numbers \\(1\\) and \\(9\\) is \\(3\\).\n",
      "\n",
      "Putting this result in the requested format, we get:\n",
      "\n",
      "\\[\n",
      "\\boxed{3}\n",
      "\\]\n",
      "\n",
      "**Confidence**: 1.0\n",
      "Answer: 3\n",
      "\n",
      "___\n",
      "Question: Factor the following quadratic: $-5 x^2-100 x$. Please put your final answer in a $\\\\boxed{}$.\n",
      "Rationale: To factor the quadratic expression \\(-5x^2 - 100x\\), we can follow these steps:\n",
      "\n",
      "1. **Identify the common factor**: We can see that both terms \\(-5x^2\\) and \\(-100x\\) share a common factor of \\(-5x\\).\n",
      "\n",
      "2. **Factor out the common factor**:\n",
      "   \\[\n",
      "   -5x^2 - 100x = -5x(x + 20)\n",
      "   \\]\n",
      "\n",
      "3. **Write the final factored form**: The expression is now factored completely.\n",
      "   Thus, the final answer is \\(-5x(x + 20)\\).\n",
      "\n",
      "Putting this into the boxed format, we have:\n",
      "\\[\n",
      "\\boxed{-5x(x + 20)}\n",
      "\\]\n",
      "\n",
      "**Confidence**: 0.95\n",
      "Answer: -5x(x + 20)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [21:41<00:00, 14.00s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.3548387096774194)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = []\n",
    "gold = []\n",
    "rationales = []\n",
    "messages = []\n",
    "\n",
    "ds = LiveBenchMathDataset()\n",
    "print(ds.get_demonstrations(\n",
    "    \"in_context_ssl/reasoning/data/livebench_math_psl_sc.hf\",\n",
    "    k=3, k_gt=0, style=\"psl\", answer=True, rationale=True, \n",
    "    quantile=0.9, seed=42\n",
    "))\n",
    "\n",
    "for inst in tqdm(ds):\n",
    "    choice = query_openai(client, inst[\"query\"], model=\"gpt-4o-mini\", structured_output=False, confidence=False)[0]\n",
    "    \n",
    "    o = parse_output_livebench_math(choice.message.content)\n",
    "\n",
    "    preds.append(o[\"answer\"])\n",
    "    gold.append(inst[\"answer\"])\n",
    "    rationales.append(o[\"rationale\"])\n",
    "    messages.append(choice.message.content)\n",
    "\n",
    "correct = np.array([grade_answer(p, g) for p, g in zip(preds, gold)]).astype(float)\n",
    "correct.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive-SemiICL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = LiveBenchMathDataset()\n",
    "\n",
    "preds = []\n",
    "gold = []\n",
    "rationales = []\n",
    "messages = []\n",
    "\n",
    "for inst in tqdm(ds.dynamic_data_selection_iter(\n",
    "    \"in_context_ssl/reasoning/data/livebench_math_psl_sc_4o.hf\",\n",
    "    k=3, answer=True, rationale=False,\n",
    "    quantile=None, seed=42\n",
    ")):\n",
    "    choice = query_openai(client, inst[\"query\"], model=\"gpt-4o\", structured_output=False, confidence=False, logprobs=False)[0]\n",
    "\n",
    "    o = parse_output_livebench_math(choice.message.content)\n",
    "\n",
    "    preds.append(o[\"answer\"])\n",
    "    gold.append(inst[\"answer\"])\n",
    "    rationales.append(o[\"rationale\"])\n",
    "    messages.append(choice.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(30, 3072), (60, 3072), (46, 3072), (32, 3072)]\n",
      "[30, 60, 46, 32]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [01:56, 42.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse error!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [14:46, 49.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse error!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29it [21:39, 47.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse error!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [23:01, 43.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse error!\n",
      "parse error!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34it [24:49, 38.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse error!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [25:17, 35.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse error!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "37it [26:55, 41.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse error!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [28:34, 36.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse error!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41it [29:36, 44.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse error!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42it [30:14, 42.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse error!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [32:21, 43.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse error!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49it [34:38, 35.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse error!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [35:06, 33.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse error!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "52it [36:16, 34.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse error!\n",
      "parse error!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [37:33, 36.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse error!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60it [40:49, 33.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse error!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [42:10, 28.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse error!\n",
      "parse error!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [45:07, 33.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse error!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "76it [49:10, 33.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse error!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [52:08, 35.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse error!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "84it [53:56, 35.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse error!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "91it [57:56, 34.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse error!\n",
      "parse error!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "93it [59:07, 38.15s/it]\n"
     ]
    }
   ],
   "source": [
    "ds = LiveBenchMathDataset()\n",
    "\n",
    "preds = []\n",
    "gold = []\n",
    "rationales = []\n",
    "messages = []\n",
    "\n",
    "for inst in tqdm(ds.mot_iter(\n",
    "    \"in_context_ssl/reasoning/data/livebench_math_psl_verbalized.hf\",\n",
    "    k=4, answer=True, rationale=True,\n",
    "    threshold=0.9, seed=42\n",
    ")):\n",
    "    choice = query_openai(client, inst[\"query\"], model=\"gpt-4o-mini\", structured_output=False, confidence=False, logprobs=False)[0]\n",
    "\n",
    "    o = parse_output_livebench_math(choice.message.content)\n",
    "\n",
    "    preds.append(o[\"answer\"])\n",
    "    gold.append(inst[\"answer\"])\n",
    "    rationales.append(o[\"rationale\"])\n",
    "    messages.append(choice.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.25806451612903225)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.array(preds)\n",
    "gold = np.array(gold)\n",
    "(preds == gold).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "275it [57:34, 12.56s/it]\n"
     ]
    }
   ],
   "source": [
    "ds = LiveBenchMathDataset()\n",
    "preds = []\n",
    "gold = []\n",
    "confidences = []\n",
    "rationales = []\n",
    "messages = []\n",
    "\n",
    "new_ds_verbalized = []\n",
    "new_ds_entropy = []\n",
    "\n",
    "for inst in tqdm(ds.train_iter(\n",
    "    \"in_context_ssl/reasoning/data/livebench_math_train.hf\", \n",
    "    k=0, answer=True, rationale=False, seed=42\n",
    ")):\n",
    "    choices = query_openai(client, inst[\"query\"], n=1, model=\"gpt-4o-mini\", structured_output=False, confidence=False, logprobs=True)\n",
    "    \"\"\"\n",
    "    o = parse_output_livebench_math(choices[0].message.content)\n",
    "    preds.append(o[\"answer\"])\n",
    "    confidences.append(o[\"confidence\"])\n",
    "    \"\"\"\n",
    "    o_verbalized = aggregate(choices, parser=parse_output_livebench_math, rationale=True, confidence=\"verbalized\")\n",
    "    o_entropy = aggregate(choices, parser=parse_output_livebench_math, rationale=True, confidence=\"entropy\")\n",
    "\n",
    "    d_verbalized = {\n",
    "        \"question\": inst[\"question\"],\n",
    "        \"answer\": o_verbalized[\"answer\"],\n",
    "        \"group\": inst[\"group\"],\n",
    "        \"rationale\": o_verbalized[\"rationale\"],\n",
    "        \"confidence\": o_verbalized[\"confidence\"],\n",
    "    }\n",
    "    d_entropy = dict(d_verbalized)\n",
    "    d_entropy[\"confidence\"] = o_entropy[\"confidence\"]\n",
    "    new_ds_verbalized.append(d_verbalized)\n",
    "    new_ds_entropy.append(d_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 275/275 [00:00<00:00, 46872.30 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 275/275 [00:00<00:00, 65291.16 examples/s]\n"
     ]
    }
   ],
   "source": [
    "datasets.Dataset.from_pandas(pd.DataFrame(new_ds_verbalized)).save_to_disk(\"in_context_ssl/reasoning/data/livebench_math_psl_k=0_verbalized_4o.hf\")\n",
    "datasets.Dataset.from_pandas(pd.DataFrame(new_ds_entropy)).save_to_disk(\"in_context_ssl/reasoning/data/livebench_math_psl_k=0_entropy_4o.hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "in-context-ssl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
