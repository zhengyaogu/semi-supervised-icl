{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhengyaogu/miniconda3/envs/in-context-ssl/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from in_context_ssl.reasoning.template import *\n",
    "import os\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import json\n",
    "from in_context_ssl.reasoning.utils import *\n",
    "from in_context_ssl.reasoning.dataset import *\n",
    "import re\n",
    "import pandas as pd\n",
    "from in_context_ssl.grading.grader import grade_answer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_doc(doc: dict):\n",
    "    out_doc = {\n",
    "        \"question\": doc[\"turns\"][0],\n",
    "        \"answer\": doc[\"ground_truth\"],\n",
    "        \"group\": doc[\"task\"]\n",
    "    }\n",
    "    return out_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data():\n",
    "    ds = load_dataset(\"livebench/math\")[\"test\"]\n",
    "\n",
    "    train_datasets = []\n",
    "    test_datasets = []\n",
    "\n",
    "    subtasks = [\"math_comp\", \"AMPS_Hard\", \"olympiad\"]\n",
    "    remove_columns = [k for k in ds.features.keys() if k not in [\"turns\", \"ground_truth\"]]\n",
    "    for subtask in subtasks:\n",
    "        print(len(ds))\n",
    "        ds_curr = ds.filter(lambda x: x[\"task\"] == subtask)\n",
    "        cutoff = int(len(ds_curr) * 0.75)\n",
    "        print(cutoff)\n",
    "        ds_curr = ds_curr.shuffle()\n",
    "        ds_train = ds_curr.select(range(cutoff)).map(process_doc, remove_columns=remove_columns)\n",
    "        ds_test = ds_curr.select(range(cutoff, len(ds_curr))).map(process_doc, remove_columns=remove_columns)\n",
    "        train_datasets.append(ds_train)\n",
    "        test_datasets.append(ds_test)\n",
    "\n",
    "    ds_train = datasets.concatenate_datasets(train_datasets)\n",
    "    ds_test = datasets.concatenate_datasets(test_datasets)\n",
    "\n",
    "    ds_train.save_to_disk(\"in_context_ssl/reasoning/data/livebench_math_train.hf\")\n",
    "    ds_test.save_to_disk(\"in_context_ssl/reasoning/data/livebench_math_test.hf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 93/93 [00:35<00:00,  2.64 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 93/93 [00:00<00:00, 19148.31 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def add_embedding(doc: dict):\n",
    "    out_doc = {\n",
    "        \"embedding\": client.embeddings.create(\n",
    "            input = [doc[\"question\"]], model=\"text-embedding-3-large\"\n",
    "        ).data[0].embedding\n",
    "    }\n",
    "    return out_doc\n",
    "ds = load_from_disk(\"in_context_ssl/reasoning/data/livebench_math_test.hf\")\n",
    "ds = ds.map(add_embedding)\n",
    "ds.save_to_disk(\"in_context_ssl/reasoning/data/livebench_math_test_new.hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add API key\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "gold = []\n",
    "rationales = []\n",
    "messages = []\n",
    "\n",
    "ds = LiveBenchMathDataset()\n",
    "print(ds.get_demonstrations(\n",
    "    \"in_context_ssl/reasoning/data/livebench_math_psl_sc.hf\",\n",
    "    k=10, style=\"psl\", answer=True, rationale=True, \n",
    "    quantile=0.9, seed=42\n",
    "))\n",
    "\n",
    "for inst in tqdm(ds):\n",
    "    choice = query_openai(client, inst[\"query\"], model=\"gpt-4o-mini\", structured_output=False, confidence=False)[0]\n",
    "    \n",
    "    o = parse_output_livebench_math(choice.message.content)\n",
    "\n",
    "    preds.append(o[\"answer\"])\n",
    "    gold.append(inst[\"answer\"])\n",
    "    rationales.append(o[\"rationale\"])\n",
    "    messages.append(choice.message.content)\n",
    "\n",
    "correct = np.array([grade_answer(p, g) for p, g in zip(preds, gold)]).astype(float)\n",
    "correct.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive-SemiICL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = LiveBenchMathDataset()\n",
    "\n",
    "preds = []\n",
    "gold = []\n",
    "rationales = []\n",
    "messages = []\n",
    "\n",
    "for inst in tqdm(ds.dynamic_data_selection_iter(\n",
    "    \"in_context_ssl/reasoning/data/livebench_math_psl_sc_4o.hf\",\n",
    "    k=3, answer=True, rationale=False,\n",
    "    quantile=None, seed=42\n",
    ")):\n",
    "    choice = query_openai(client, inst[\"query\"], model=\"gpt-4o\", structured_output=False, confidence=False, logprobs=False)[0]\n",
    "\n",
    "    o = parse_output_livebench_math(choice.message.content)\n",
    "\n",
    "    preds.append(o[\"answer\"])\n",
    "    gold.append(inst[\"answer\"])\n",
    "    rationales.append(o[\"rationale\"])\n",
    "    messages.append(choice.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "in-context-ssl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
